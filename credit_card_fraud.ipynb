{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "credit_card_fraud.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssawant/ml-jupyter-notebook/blob/master/credit_card_fraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pAWwMXIu6xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvZqr9hv5fyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HDfqcyYYG54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La1xhypkYUKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip train_identity.csv.zip\n",
        "!unzip train_transaction.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyLGFcwAYgLx",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGQzfJsfYji5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_train_id = pd.read_csv('train_identity.csv')\n",
        "df_train_tran = pd.read_csv('train_transaction.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDoa1tDQJDLY",
        "colab_type": "text"
      },
      "source": [
        "Helper function to reduce dataframe memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3d4e6OLJHm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credit to @guiferviz for the memory reduction \n",
        "def memory_usage_mb(df, *args, **kwargs):\n",
        "    \"\"\"Dataframe memory usage in MB. \"\"\"\n",
        "    return df.memory_usage(*args, **kwargs).sum() / 1024**2\n",
        "\n",
        "def reduce_memory_usage(df, deep=True, verbose=True):\n",
        "    # All types that we want to change for \"lighter\" ones.\n",
        "    # int8 and float16 are not include because we cannot reduce\n",
        "    # those data types.\n",
        "    # float32 is not include because float16 has too low precision.\n",
        "    numeric2reduce = [\"int16\", \"int32\", \"int64\", \"float64\"]\n",
        "    start_mem = 0\n",
        "    if verbose:\n",
        "        start_mem = memory_usage_mb(df, deep=deep)\n",
        "\n",
        "    for col, col_type in df.dtypes.iteritems():\n",
        "        best_type = None\n",
        "        if col_type in numeric2reduce:\n",
        "            downcast = \"integer\" if \"int\" in str(col_type) else \"float\"\n",
        "            df[col] = pd.to_numeric(df[col], downcast=downcast)\n",
        "            best_type = df[col].dtype.name\n",
        "        # Log the conversion performed.\n",
        "        if verbose and best_type is not None and best_type != str(col_type):\n",
        "            print(f\"Column '{col}' converted from {col_type} to {best_type}\")\n",
        "    \n",
        "    if verbose:\n",
        "        end_mem = memory_usage_mb(df, deep=deep)\n",
        "        diff_mem = start_mem - end_mem\n",
        "        percent_mem = 100 * diff_mem / start_mem\n",
        "        print(f\"Memory usage decreased from\"\n",
        "              f\" {start_mem:.2f}MB to {end_mem:.2f}MB\"\n",
        "              f\" ({diff_mem:.2f}MB, {percent_mem:.2f}% reduction)\")\n",
        "        \n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf8zrYEqahy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.merge(df_train_tran, df_train_id, on='TransactionID', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh_tvagTa-QY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Train dataset has {df_train.shape[0]} rows and {df_train.shape[1]} columns.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYSP1ZcDbR9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df_train_tran, df_train_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSDcxaqsblhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_train.head()\n",
        "memory_usage_mb(df_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpUC6NbJb367",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "count = df_train['isFraud'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.barplot(count.index, count.values, alpha=0.8)\n",
        "plt.ylabel('no of transactions', fontsize=12)\n",
        "plt.xlabel('is transaction fraud or not?', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGHiiN2xcyUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_data_sample = len(df_train.index)\n",
        "\n",
        "input_features_missing_proportions = df_train.isnull().sum() / no_data_sample\n",
        "\n",
        "plt.hist(input_features_missing_proportions)\n",
        "plt.title('Proportion of Missing Values in Input Features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksH3mTlHePe1",
        "colab_type": "text"
      },
      "source": [
        "Removing columns which has more then 60% nan values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKZ3sVbneGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.loc[:, df_train.isnull().mean() <=.6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_33AJDFRevJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.shape\n",
        "memory_usage_mb(df_train) # 937 MB reduction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhljJ3hYfBXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = df_train['card4'].value_counts()\n",
        "\n",
        "sns.barplot(count.index, count.values, alpha=0.8)\n",
        "plt.ylabel('no of transactions', fontsize=12)\n",
        "plt.xlabel('type of cards', fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsZaGGgugdwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.select_dtypes(exclude=['int', 'float']).columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behn2jYrg4mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_col = df_train._get_numeric_data().columns\n",
        "numeric_col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzwftA_kg4ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "memory_usage_mb(df_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLR_taeFi9aN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replacing null missing value with mean of dataset\n",
        "numeric_column = [i for i in numeric_col]\n",
        "for i in numeric_column:\n",
        "  df_train[i]=df_train[i].fillna(df_train[i].median())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZRw39x6jPwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_num = df_train[numeric_column]\n",
        "data_num.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O08siAsFjlJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cat = df_train.select_dtypes(exclude=['int', 'float']).columns\n",
        "num_cat = [i for i in num_cat]\n",
        "num_cat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaaZuJ3ZkRpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(strategy='most_frequent')\n",
        "imp.fit(df_train[num_cat])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxSNZWb6ly10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train[num_cat] = imp.transform(df_train[num_cat])\n",
        "data_cat = df_train[num_cat]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGrBC06-mFPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cat.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ1tJv5snzer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding no of category in categorical columns\n",
        "data_cat = data_cat.astype('category')\n",
        "cat_level = data_cat.apply(lambda col: len(col.cat.categories))\n",
        "cat_level"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dab3PGc-3paL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClFzO_qy5mfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_cat = pd.get_dummies(data_cat[num_cat])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa9l98wr6dC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([data_num, data_cat], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zfgGgls7UQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del df_train\n",
        "del data_num\n",
        "del data_cat\n",
        "# del cat_level\n",
        "!free -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds1n13EtCEok",
        "colab_type": "text"
      },
      "source": [
        "Traning and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3NMIkpvM_Rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = reduce_memory_usage(df, deep=True, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSRW-rwuCER0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.iloc[:,3:], df['isFraud'], test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fn8CnCWF0Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmSBmOzer76H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scipy.stats import uniform\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from sklearn.linear_model import SGDClassifier\n",
        "# import scipy\n",
        "# tuned_parameters ={'penalty':['l1','l2','elasticnet'],'alpha':[500,100,50,10,5,1,0.5,0.1,0.05,0.01,0.005,0.001,0.0005,0.0001,0.00005,0.00001]}\n",
        "\n",
        "# model = RandomizedSearchCV(SGDClassifier(),param_distributions=tuned_parameters,scoring='roc_auc',n_jobs = -1)\n",
        "# model.fit(X_train, y_train)\n",
        "# pred=model.predict(y_val)\n",
        "# conf_mat = confusion_matrix(y_val, pred)\n",
        "# sns.heatmap(conf_mat,annot=True,fmt=\"d\",linewidths=.5)\n",
        "# plt.show()\n",
        "\n",
        "# print(\"The best parameters are %s with a score of %0.2f\"% (model.best_params_, model.best_score_))\n",
        "# sgd_churn_result = roc_auc_score(churn_test_y, pred)\n",
        "# print(\"roc_auc for Churn is: %0.3f\"%(roc_auc_score(y_val, pred)))\n",
        "# print(\"Precision for Churn is: %0.3f\"%(precision_score(y_val, pred)))\n",
        "# print(\"Recall for Churn is: %0.3f\"%(recall_score(y_val, pred)))\n",
        "# print(\"F1-Score for Churn is: %0.3f\"%(f1_score(y_val, pred)))\n",
        "\n",
        "# Logistic Regression model\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# lr = LogisticRegression()\n",
        "\n",
        "# # Train the model using 'fit' method\n",
        "# lr.fit(X_train, y_train)\n",
        "\n",
        "# # Test the model using 'predict' method\n",
        "# y_pred = lr.predict(X_val)\n",
        "\n",
        "# # Print the classification report\n",
        "# from sklearn.metrics import classification_report\n",
        "# print(classification_report(y_val, y_pred))\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB \n",
        "\n",
        "# Train LogisticRegression Model\n",
        "LGR_Classifier = LogisticRegression(max_iter=500)\n",
        "LGR_Classifier.fit(X_train, y_train)\n",
        "\n",
        "# Train Decision Tree Model\n",
        "RDF_Classifier = RandomForestClassifier(random_state=0)\n",
        "RDF_Classifier.fit(X_train, y_train)\n",
        "\n",
        "# Train Bernoulli Navi Baye Model\n",
        "BNB_Classifier = BernoulliNB()\n",
        "BNB_Classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxP3ad6G8Kzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate Models\n",
        "modelist = [('RandomForest Classifier', RDF_Classifier), ('LogisticRegression', LGR_Classifier), ('Navi Baiya Classifier', BNB_Classifier)]\n",
        "\n",
        "models = [j for j in modelist]\n",
        "\n",
        "print('================ Model Evaluation Results ===================' \"\\n\")\n",
        "\n",
        "for i, v in models:\n",
        "  scores = cross_val_score(v, X_train, y_train, cv=10)\n",
        "  accuracy = metrics.accuracy_score(y_train, v.predict(X_train))\n",
        "  confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_train))\n",
        "  classification = metrics.classification_report(y_train, v.predict(X_train))\n",
        "  print(f'============{i}============')\n",
        "  print()\n",
        "  print(f'Cross Validation Mean Score: {np.round(scores.mean(), 3) * 100}')\n",
        "  print()\n",
        "  print(f'Model Accuracy: {np.round(accuracy, 3) * 100}')\n",
        "  print()\n",
        "  print(f'Confusion Matrix: \\n{confusion_matrix}')\n",
        "  print()\n",
        "  print(f'Classification Report: \\n{classification}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb0CtLNqBQmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Model\n",
        "classdict = {'normal':0, 'fraudulent':1}\n",
        "print()\n",
        "print('===================== Model Test Result ======================' \"\\n\")\n",
        "\n",
        "for i, v in models:\n",
        "  accuracy = metrics.accuracy_score(y_val, v.predict(X_val))\n",
        "  confusion_matrix = metrics.confusion_matrix(y_val, v.predict)(X_val)\n",
        "  classification = metrics.classification_report(y_val, v.predict(X_val))\n",
        "  print(f'======== {i} =========')\n",
        "  print (f'Model Accuracy: {np.round(accuracy, 3) * 100)}')\n",
        "  print()\n",
        "  print(f'Confusion Matrix: {confusion_matrix}')\n",
        "  print()\n",
        "  pf.plot_confusion_matrix(confusion_matrix, classes = list(classdict.keys()), title='Confusion Matrix Plot', cmap=plt.cm.summer)\n",
        "  print() \n",
        "  print(f'Classification Report: \\n{classification}') \n",
        "  print() \n",
        "\n",
        "print('============================= ROC Curve ===============================' \"\\n\")      \n",
        "pf.plot_roc_auc(arg1=models, arg2=X_test, arg3=y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}